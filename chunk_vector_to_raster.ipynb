{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c50baa4-6c47-4bb7-a6ce-10c6ed7e2ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "!gdalbuildvrt output.vrt ./chunked_rasters/*.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8bc814-c7d8-4301-aa5c-a83abc754ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ac432c-68d5-465b-a4e8-e28d18b741cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from osgeo import ogr, gdal, gdalconst\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def rasterize_chunk(vector_file, raster_template, chunk_extents, output_raster, burn_value=1):\n",
    "    \"\"\"Rasterizes a chunk of the vector file based on specified extents.\"\"\"\n",
    "    raster_template_ds = gdal.Open(raster_template, gdalconst.GA_ReadOnly)\n",
    "    if raster_template_ds is None:\n",
    "        raise FileNotFoundError(f\"Unable to open raster template: {raster_template}\")\n",
    "    \n",
    "    geotransform = raster_template_ds.GetGeoTransform()\n",
    "    projection = raster_template_ds.GetProjection()\n",
    "    pixel_width = geotransform[1]\n",
    "    pixel_height = -geotransform[5]\n",
    "    \n",
    "    # Calculate output raster dimensions\n",
    "    x_min, x_max, y_min, y_max = chunk_extents\n",
    "    xsize = int((x_max - x_min) / pixel_width)\n",
    "    ysize = int((y_max - y_min) / pixel_height)\n",
    "    \n",
    "    # Create the output raster for this chunk\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    dst_ds = driver.Create(output_raster, xsize, ysize, 1, gdalconst.GDT_Byte, options=[\"COMPRESS=DEFLATE\", \"PREDICTOR=2\", \"ZLEVEL=9\"])\n",
    "    dst_ds.SetGeoTransform((x_min, pixel_width, 0, y_max, 0, -pixel_height))\n",
    "    dst_ds.SetProjection(projection)\n",
    "    \n",
    "    dst_band = dst_ds.GetRasterBand(1)\n",
    "    dst_band.SetNoDataValue(0)\n",
    "    dst_band.Fill(0)\n",
    "    \n",
    "    # Rasterize the vector layer into this chunk\n",
    "    vector_ds = ogr.Open(vector_file)\n",
    "    vector_layer = vector_ds.GetLayer()\n",
    "    gdal.RasterizeLayer(dst_ds, [1], vector_layer, burn_values=[burn_value])\n",
    "    \n",
    "    # Close datasets\n",
    "    dst_ds = None\n",
    "    raster_template_ds = None\n",
    "    vector_ds = None\n",
    "    print(f\"Processed chunk: {output_raster}\")\n",
    "\n",
    "\n",
    "def split_into_chunks(extents, chunk_size):\n",
    "    \"\"\"Splits the full raster extents into smaller chunks for parallel processing.\"\"\"\n",
    "    x_min, x_max, y_min, y_max = extents\n",
    "    chunks = []\n",
    "    x = x_min\n",
    "    while x < x_max:\n",
    "        y = y_min\n",
    "        while y < y_max:\n",
    "            chunk_x_max = min(x + chunk_size, x_max)\n",
    "            chunk_y_max = min(y + chunk_size, y_max)\n",
    "            chunks.append((x, chunk_x_max, y, chunk_y_max))\n",
    "            y += chunk_size\n",
    "        x += chunk_size\n",
    "    return chunks\n",
    "\n",
    "def parallel_rasterize_to_chunks(vector_file, raster_template, output_folder, chunk_size, burn_value=1):\n",
    "    \"\"\"Rasterizes the vector file to the given raster resolution using parallel processing.\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    raster_template_ds = gdal.Open(raster_template, gdalconst.GA_ReadOnly)\n",
    "    if raster_template_ds is None:\n",
    "        raise FileNotFoundError(f\"Unable to open raster template: {raster_template}\")\n",
    "    \n",
    "    geotransform = raster_template_ds.GetGeoTransform()\n",
    "    xsize, ysize = raster_template_ds.RasterXSize, raster_template_ds.RasterYSize\n",
    "    \n",
    "    x_min = geotransform[0]\n",
    "    x_max = x_min + xsize * geotransform[1]\n",
    "    y_max = geotransform[3]\n",
    "    y_min = y_max + ysize * geotransform[5]\n",
    "    \n",
    "    raster_template_ds = None  # Close the template raster\n",
    "    \n",
    "    # Split the raster extents into chunks\n",
    "    chunks = split_into_chunks((x_min, x_max, y_min, y_max), chunk_size)\n",
    "    temp_rasters = [os.path.join(output_folder, f\"chunk_{i}.tif\") for i in range(len(chunks))]\n",
    "    \n",
    "    # Prepare arguments for parallel processing\n",
    "    args = [\n",
    "        (vector_file, raster_template, chunks[i], temp_rasters[i], burn_value)\n",
    "        for i in range(len(chunks))\n",
    "    ]\n",
    "    \n",
    "    # Process chunks in parallel\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        pool.starmap(rasterize_chunk, args)\n",
    "    \n",
    "    print(f\"Rasterization complete. Chunked rasters saved in {output_folder}\")\n",
    "\n",
    "# Example usage\n",
    "vector_file = \"/media/dave/3230-6239/IACS_20240715/iacs_lines.shp\"\n",
    "raster_template = \"/media/dave/windows_OS/lidar/Export/6-Above15m_compressed.tif\"\n",
    "output_folder = \"./chunked_rasters\"\n",
    "chunk_size = 10000  # 10km by 10km chunks\n",
    "\n",
    "parallel_rasterize_to_chunks(vector_file, raster_template, output_folder, chunk_size, burn_value=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1752b6c-fc87-49bd-91b0-a1e23c36c8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087cdbc-ba74-40e7-bce4-f2f302de2eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#virtual merge rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dfc16c-c31c-4568-b060-3469c02fe5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalbuildvrt output.vrt ./chunked_rasters/*.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54296a00-225c-4435-921f-d76fdb01ce26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing raster: ./chunked_rasters/chunk_270.tif\n",
      "Processing raster: ./chunked_rasters/chunk_426.tif\n",
      "Processing raster: ./chunked_rasters/chunk_203.tif\n",
      "Processing raster: ./chunked_rasters/chunk_405.tif\n",
      "Processing raster: ./chunked_rasters/chunk_202.tif\n",
      "Processing raster: ./chunked_rasters/chunk_21.tif\n",
      "Processing raster: ./chunked_rasters/chunk_178.tif\n",
      "Processing raster: ./chunked_rasters/chunk_159.tif\n",
      "Processing raster: ./chunked_rasters/chunk_347.tif\n",
      "Processing raster: ./chunked_rasters/chunk_501.tif\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1000,1000) (1000,871) (1000,1000) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 112\u001b[0m\n\u001b[1;32m    109\u001b[0m min_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    110\u001b[0m max_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[0;32m--> 112\u001b[0m \u001b[43mprocess_folder_rasters\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_raster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 83\u001b[0m, in \u001b[0;36mprocess_folder_rasters\u001b[0;34m(input_folder, output_raster, min_threshold, max_threshold, chunk_size, compression)\u001b[0m\n\u001b[1;32m     81\u001b[0m         combined_geotransform \u001b[38;5;241m=\u001b[39m geotransform\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m         combined_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m output_data  \u001b[38;5;66;03m# Merge the data\u001b[39;00m\n\u001b[1;32m     85\u001b[0m xsize, ysize \u001b[38;5;241m=\u001b[39m combined_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], combined_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     86\u001b[0m driver \u001b[38;5;241m=\u001b[39m gdal\u001b[38;5;241m.\u001b[39mGetDriverByName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGTiff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1000,1000) (1000,871) (1000,1000) "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from osgeo import gdal, gdalconst\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "\n",
    "def process_chunk_parallel(args):\n",
    "    \"\"\"Worker function to process a single chunk in parallel.\"\"\"\n",
    "    src_raster, x, y, x_end, y_end, min_threshold, max_threshold, nodata = args\n",
    "    src_ds = gdal.Open(src_raster, gdalconst.GA_ReadOnly)\n",
    "    src_band = src_ds.GetRasterBand(1)\n",
    "    chunk_data = src_band.ReadAsArray(x, y, x_end - x, y_end - y)\n",
    "    src_ds = None\n",
    "    \n",
    "    # Apply threshold\n",
    "    mask = (chunk_data >= min_threshold) & (chunk_data <= max_threshold)\n",
    "    chunk_data = np.where(mask, 1, 0)  # Reclassify\n",
    "    \n",
    "    # Resample to 10m resolution\n",
    "    chunk_resampled = chunk_data.reshape(\n",
    "        (chunk_data.shape[0] // 10, 10, chunk_data.shape[1] // 10, 10)\n",
    "    ).sum(axis=(1, 3))  # Sum within 10x10 blocks\n",
    "    \n",
    "    return x, y, chunk_resampled\n",
    "\n",
    "\n",
    "def process_large_raster(input_raster, output_raster, min_threshold, max_threshold, chunk_size=10000, compression=\"DEFLATE\"):\n",
    "    \"\"\"Main function to process large raster in parallel.\"\"\"\n",
    "    # Open the input raster\n",
    "    src_ds = gdal.Open(input_raster, gdalconst.GA_ReadOnly)\n",
    "    if src_ds is None:\n",
    "        raise FileNotFoundError(f\"Unable to open input raster: {input_raster}\")\n",
    "    \n",
    "    src_band = src_ds.GetRasterBand(1)\n",
    "    nodata = src_band.GetNoDataValue()\n",
    "    if nodata is None:\n",
    "        nodata = 0\n",
    "    \n",
    "    # Get raster dimensions and geotransform\n",
    "    xsize, ysize = src_ds.RasterXSize, src_ds.RasterYSize\n",
    "    geotransform = src_ds.GetGeoTransform()\n",
    "    projection = src_ds.GetProjection()\n",
    "    \n",
    "    # Prepare output raster\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst_ds = driver.Create(\n",
    "        output_raster,\n",
    "        xsize // 10,  # Resampled to 10m resolution\n",
    "        ysize // 10,\n",
    "        1,\n",
    "        gdalconst.GDT_Int32,\n",
    "        options=[\"COMPRESS={}\".format(compression)]\n",
    "    )\n",
    "    dst_ds.SetGeoTransform((\n",
    "        geotransform[0], 10, 0, geotransform[3], 0, -10\n",
    "    ))  # Update geotransform for 10m resolution\n",
    "    dst_ds.SetProjection(projection)\n",
    "    dst_band = dst_ds.GetRasterBand(1)\n",
    "    dst_band.SetNoDataValue(0)\n",
    "    \n",
    "    # Determine chunk size in pixels\n",
    "    chunk_x_pixels = int(chunk_size // abs(geotransform[1]))  # Convert chunk size to pixels (meters -> pixels)\n",
    "    chunk_y_pixels = int(chunk_size // abs(geotransform[5]))\n",
    "    \n",
    "    # Create tasks for parallel processing\n",
    "    tasks = []\n",
    "    for y in range(0, ysize, chunk_y_pixels):\n",
    "        for x in range(0, xsize, chunk_x_pixels):\n",
    "            x_end = min(x + chunk_x_pixels, xsize)\n",
    "            y_end = min(y + chunk_y_pixels, ysize)\n",
    "            tasks.append((input_raster, x, y, x_end, y_end, min_threshold, max_threshold, nodata))\n",
    "    \n",
    "    # Use multiprocessing to process chunks in parallel\n",
    "    print(f\"Using {cpu_count()} processors...\")\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        results = pool.map(process_chunk_parallel, tasks)\n",
    "    \n",
    "    # Combine results into the output array\n",
    "    output_data = np.zeros((ysize // 10, xsize // 10), dtype=np.int32)\n",
    "    for x, y, chunk_resampled in results:\n",
    "        res_y_start = y // 10\n",
    "        res_x_start = x // 10\n",
    "        output_data[res_y_start:res_y_start + chunk_resampled.shape[0], \n",
    "                    res_x_start:res_x_start + chunk_resampled.shape[1]] += chunk_resampled\n",
    "    \n",
    "    # Write output raster\n",
    "    dst_band.WriteArray(output_data)\n",
    "    dst_band.FlushCache()\n",
    "    dst_ds = None\n",
    "    src_ds = None\n",
    "    print(f\"Processing complete: {output_raster}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_raster = \"output.vrt\"\n",
    "output_raster = \"lpis_10m.tif\"\n",
    "\n",
    "# Define threshold range\n",
    "min_threshold = 1\n",
    "max_threshold = 6666\n",
    "\n",
    "process_large_raster(input_raster, output_raster, min_threshold, max_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "196f9a40-658c-4e67-9292-21d0a99200e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing raster: ./chunked_rasters/chunk_270.tif\n",
      "Processing raster: ./chunked_rasters/chunk_426.tif\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (1000,1000) into shape (0,0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 131\u001b[0m\n\u001b[1;32m    128\u001b[0m min_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    129\u001b[0m max_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[0;32m--> 131\u001b[0m \u001b[43mprocess_folder_rasters\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_raster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 94\u001b[0m, in \u001b[0;36mprocess_folder_rasters\u001b[0;34m(input_folder, output_raster, min_threshold, max_threshold, chunk_size, compression)\u001b[0m\n\u001b[1;32m     91\u001b[0m combined_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(target_shape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m raster_file \u001b[38;5;129;01min\u001b[39;00m raster_files:\n\u001b[0;32m---> 94\u001b[0m     output_data \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_single_raster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraster_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_geotransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# Ensure the raster dimensions match the combined data before adding\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_data\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m combined_data\u001b[38;5;241m.\u001b[39mshape:\n",
      "Cell \u001b[0;32mIn[4], line 62\u001b[0m, in \u001b[0;36mprocess_single_raster\u001b[0;34m(input_raster, min_threshold, max_threshold, chunk_size, target_geotransform, target_shape)\u001b[0m\n\u001b[1;32m     58\u001b[0m     output_data[res_y_start:res_y_start \u001b[38;5;241m+\u001b[39m chunk_resampled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \n\u001b[1;32m     59\u001b[0m                 res_x_start:res_x_start \u001b[38;5;241m+\u001b[39m chunk_resampled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m chunk_resampled\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Align to target extent and shape\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m aligned_data \u001b[38;5;241m=\u001b[39m \u001b[43malign_to_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeotransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_geotransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m aligned_data\n",
      "Cell \u001b[0;32mIn[4], line 73\u001b[0m, in \u001b[0;36malign_to_target\u001b[0;34m(data, source_geotransform, target_geotransform, target_shape, nodata)\u001b[0m\n\u001b[1;32m     71\u001b[0m aligned_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(target_shape, nodata, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m     72\u001b[0m ysize, xsize \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 73\u001b[0m \u001b[43maligned_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43msrc_y_offset\u001b[49m\u001b[43m:\u001b[49m\u001b[43msrc_y_offset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mysize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_x_offset\u001b[49m\u001b[43m:\u001b[49m\u001b[43msrc_x_offset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mxsize\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m aligned_data\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (1000,1000) into shape (0,0)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from osgeo import gdal, gdalconst\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def process_chunk_parallel(args):\n",
    "    \"\"\"Worker function to process a single chunk in parallel.\"\"\"\n",
    "    src_raster, x, y, x_end, y_end, min_threshold, max_threshold, nodata = args\n",
    "    src_ds = gdal.Open(src_raster, gdalconst.GA_ReadOnly)\n",
    "    src_band = src_ds.GetRasterBand(1)\n",
    "    chunk_data = src_band.ReadAsArray(x, y, x_end - x, y_end - y)\n",
    "    src_ds = None\n",
    "    \n",
    "    # Apply threshold\n",
    "    mask = (chunk_data >= min_threshold) & (chunk_data <= max_threshold)\n",
    "    chunk_data = np.where(mask, 1, 0)  # Reclassify\n",
    "    \n",
    "    # Resample to 10m resolution\n",
    "    chunk_resampled = chunk_data.reshape(\n",
    "        (chunk_data.shape[0] // 10, 10, chunk_data.shape[1] // 10, 10)\n",
    "    ).sum(axis=(1, 3))  # Sum within 10x10 blocks\n",
    "    \n",
    "    return x, y, chunk_resampled\n",
    "\n",
    "def process_single_raster(input_raster, min_threshold, max_threshold, chunk_size, target_geotransform, target_shape):\n",
    "    \"\"\"Processes a single raster and returns the aligned resampled output.\"\"\"\n",
    "    src_ds = gdal.Open(input_raster, gdalconst.GA_ReadOnly)\n",
    "    if src_ds is None:\n",
    "        raise FileNotFoundError(f\"Unable to open input raster: {input_raster}\")\n",
    "    \n",
    "    src_band = src_ds.GetRasterBand(1)\n",
    "    nodata = src_band.GetNoDataValue()\n",
    "    if nodata is None:\n",
    "        nodata = 0\n",
    "    \n",
    "    xsize, ysize = src_ds.RasterXSize, src_ds.RasterYSize\n",
    "    geotransform = src_ds.GetGeoTransform()\n",
    "    \n",
    "    chunk_x_pixels = int(chunk_size // abs(geotransform[1]))\n",
    "    chunk_y_pixels = int(chunk_size // abs(geotransform[5]))\n",
    "    \n",
    "    tasks = []\n",
    "    for y in range(0, ysize, chunk_y_pixels):\n",
    "        for x in range(0, xsize, chunk_x_pixels):\n",
    "            x_end = min(x + chunk_x_pixels, xsize)\n",
    "            y_end = min(y + chunk_y_pixels, ysize)\n",
    "            tasks.append((input_raster, x, y, x_end, y_end, min_threshold, max_threshold, nodata))\n",
    "    \n",
    "    print(f\"Processing raster: {input_raster}\")\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        results = pool.map(process_chunk_parallel, tasks)\n",
    "    \n",
    "    output_data = np.zeros((ysize // 10, xsize // 10), dtype=np.int32)\n",
    "    for x, y, chunk_resampled in results:\n",
    "        res_y_start = y // 10\n",
    "        res_x_start = x // 10\n",
    "        output_data[res_y_start:res_y_start + chunk_resampled.shape[0], \n",
    "                    res_x_start:res_x_start + chunk_resampled.shape[1]] += chunk_resampled\n",
    "    \n",
    "    # Align to target extent and shape\n",
    "    aligned_data = align_to_target(output_data, geotransform, target_geotransform, target_shape, nodata=0)\n",
    "    return aligned_data\n",
    "\n",
    "\n",
    "def align_to_target(data, source_geotransform, target_geotransform, target_shape, nodata=0):\n",
    "    \"\"\"Aligns raster data to a target geotransform and shape by padding or cropping.\"\"\"\n",
    "    src_x_offset = int((source_geotransform[0] - target_geotransform[0]) / target_geotransform[1])\n",
    "    src_y_offset = int((source_geotransform[3] - target_geotransform[3]) / target_geotransform[5])\n",
    "    \n",
    "    aligned_data = np.full(target_shape, nodata, dtype=np.int32)\n",
    "    ysize, xsize = data.shape\n",
    "    aligned_data[src_y_offset:src_y_offset + ysize, src_x_offset:src_x_offset + xsize] = data\n",
    "    return aligned_data\n",
    "\n",
    "\n",
    "def process_folder_rasters(input_folder, output_raster, min_threshold, max_threshold, chunk_size=10000, compression=\"DEFLATE\"):\n",
    "    \"\"\"Processes all rasters in a folder and merges results.\"\"\"\n",
    "    raster_files = glob.glob(os.path.join(input_folder, \"*.tif\"))\n",
    "    if not raster_files:\n",
    "        raise FileNotFoundError(f\"No rasters found in folder: {input_folder}\")\n",
    "    \n",
    "    # Determine the target extent and shape from the first raster\n",
    "    first_raster = gdal.Open(raster_files[0], gdalconst.GA_ReadOnly)\n",
    "    target_geotransform = first_raster.GetGeoTransform()\n",
    "    target_xsize = first_raster.RasterXSize // 10\n",
    "    target_ysize = first_raster.RasterYSize // 10\n",
    "    target_shape = (target_ysize, target_xsize)\n",
    "    first_raster = None\n",
    "    \n",
    "    combined_data = np.zeros(target_shape, dtype=np.int32)\n",
    "    \n",
    "    for raster_file in raster_files:\n",
    "        output_data = process_single_raster(raster_file, min_threshold, max_threshold, chunk_size, target_geotransform, target_shape)\n",
    "        \n",
    "        # Ensure the raster dimensions match the combined data before adding\n",
    "        if output_data.shape != combined_data.shape:\n",
    "            raise ValueError(f\"Shape mismatch: {output_data.shape} vs {combined_data.shape}\")\n",
    "        \n",
    "        combined_data += output_data  # Merge the data\n",
    "    \n",
    "    # Write the combined raster to file\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst_ds = driver.Create(\n",
    "        output_raster,\n",
    "        target_shape[1],\n",
    "        target_shape[0],\n",
    "        1,\n",
    "        gdalconst.GDT_Int32,\n",
    "        options=[\"COMPRESS={}\".format(compression)]\n",
    "    )\n",
    "    dst_ds.SetGeoTransform((\n",
    "        target_geotransform[0], 10, 0, target_geotransform[3], 0, -10\n",
    "    ))\n",
    "    dst_band = dst_ds.GetRasterBand(1)\n",
    "    dst_band.SetNoDataValue(0)\n",
    "    dst_band.WriteArray(combined_data)\n",
    "    dst_band.FlushCache()\n",
    "    dst_ds = None\n",
    "    print(f\"Processing complete: {output_raster}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_folder = \"./chunked_rasters\"  # Folder containing chunked rasters\n",
    "output_raster = \"LPIS_chunked_10m.tif\"  # Output raster file\n",
    "\n",
    "# Define threshold range\n",
    "min_threshold = 1\n",
    "max_threshold = 300\n",
    "\n",
    "process_folder_rasters(input_folder, output_raster, min_threshold, max_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f4386-9a92-41bb-96f3-a8a2b2e0d959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
